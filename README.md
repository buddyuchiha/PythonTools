# Асинхронный веб-краулер

Асинхронный веб-краулер для одновременной обработки нескольких веб-страниц с извлечением заголовков и статусов

## Функционал

* Асинхронные HTTP-запросы к множеству URL одновременно
* Извлечение заголовков страниц и HTTP-статусов
* Ограничение скорости запросов для избежания блокировки
* Обработка таймаутов и ошибок подключения
* Сохранение результатов в структурированный JSON-файл

## Технологии

![AsyncIO](https://img.shields.io/badge/-AsyncIO-3776AB?logo=python&logoColor=white)
![HTTP](https://img.shields.io/badge/-HTTP%20Requests-FF6B35?logo=aiohttp&logoColor=white)
![BeautifulSoup](https://img.shields.io/badge/-HTML%20Parsing-4B8BBE?logo=beautifulsoup&logoColor=white)
![JSON](https://img.shields.io/badge/-JSON%20Export-000000?logo=json&logoColor=white)

## Установка
1) Копирование git-репозитория https://github.com/buddyuchiha/PythonTools.git

<img width="993" height="154" alt="image" src="https://github.com/user-attachments/assets/dd019592-6b48-49b5-9579-abae986b78d2" />

2) Открыть проект

<img width="631" height="47" alt="image" src="https://github.com/user-attachments/assets/85195bc3-c201-44c3-9b86-070ba82a9a93" />

3) Перейти на ветку async-aiohttp-practice

<img width="590" height="56" alt="image" src="https://github.com/user-attachments/assets/94df326e-e65e-4e54-b492-82c090dd5330" />

4) Создать виртуальное окружение и установить зависимости

<img width="569" height="61" alt="image" src="https://github.com/user-attachments/assets/dcc1169b-69ff-4a96-bb01-faaf2abf2823" />

5) Запустить проект

<img width="850" height="63" alt="image" src="https://github.com/user-attachments/assets/531c13c2-7b98-4494-912e-32f2d907ad98" />

Адреса указаны в config.yaml

<img width="506" height="182" alt="image" src="https://github.com/user-attachments/assets/b164d6db-921c-4140-927d-f7f2356cd92a" />

Результаты

<img width="768" height="494" alt="image" src="https://github.com/user-attachments/assets/39132d16-5da3-499b-bbe0-ebad478f1ab4" />
